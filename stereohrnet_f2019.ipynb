{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "stereohrnet-f2019.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudhs001/3D-ObjectDetection/blob/main/stereohrnet_f2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ipTHOqNzrK2",
        "outputId": "42ceb160-88d8-48e1-9d0e-d55eaef350e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8GZKdc61P_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbac052-386d-42ef-cb05-66b3f4dce193"
      },
      "source": [
        "cp -r drive/MyDrive/playground/training . "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'drive/MyDrive/playground/training': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-15T12:13:13.715109Z",
          "iopub.execute_input": "2021-06-15T12:13:13.715574Z",
          "iopub.status.idle": "2021-06-15T12:13:16.086734Z",
          "shell.execute_reply.started": "2021-06-15T12:13:13.715481Z",
          "shell.execute_reply": "2021-06-15T12:13:16.085540Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiG2lEVazdYx",
        "outputId": "66df0909-02c4-4ef7-cabe-8a7b73c63edc"
      },
      "source": [
        "# pip uninstall opencv-contrib-python opencv-python -y\n",
        "# !pip install opencv-contrib-python\n",
        "# !pip install fastai==1.0.61\n",
        "!pip freeze | grep fast*\n",
        "# !pip3 install 'pillow < 7.0.0'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cAbDScR7zdY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae910898-e937-4da2-f103-ef3ac88f4a2b"
      },
      "source": [
        "!pwd\n",
        "!mkdir -p StereoHRnet/models\n",
        "!cd ../input/pretrained-model-epoch-25/; cp model_epoch_36.pth /kaggle/working/StereoHRnet/models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/bin/bash: line 0: cd: ../input/pretrained-model-epoch-25/: No such file or directory\n",
            "cp: cannot stat 'model_epoch_36.pth': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxJyAO8pzdY6"
      },
      "source": [
        "\n",
        "### **TARGET_VECTOR** = [\\<one-hot-vector for 9 classes == 9 0/1s\\>, \\<2D bbox\\>, \\<dimensions\\>, \\<location\\>, \\<rotation_y\\>]   \n",
        "total 20 values in single vector    \n",
        "each target matrix has 32x32 such vectors\n",
        "\n",
        "where,\n",
        "\n",
        "**bbox 2D** = (0-based) bounding box of the object: Left, top, right, bottom image coordinates\n",
        "\n",
        "**dimensions** = 3D object dimensions: height, width, length [m]\n",
        "\n",
        "**location** = 3D object location x,y,z in camera coords. [m]\n",
        "\n",
        "**rotation_y** = Rotation around Y-axis in camera coords. [-Pi; Pi]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHr-t4RGnBPU"
      },
      "source": [
        "\n",
        "# Imports and pre-steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfUQ0EQPJ8zd",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:52:57.010170Z",
          "iopub.execute_input": "2021-06-15T02:52:57.010527Z",
          "iopub.status.idle": "2021-06-15T02:52:57.462299Z",
          "shell.execute_reply.started": "2021-06-15T02:52:57.010477Z",
          "shell.execute_reply": "2021-06-15T02:52:57.461473Z"
        },
        "trusted": true
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "# from torchvision.transforms.functional import InterpolationMode\n",
        "import cv2\n",
        "from cv2 import cvtColor\n",
        "import imageio as io\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25by7ziiz4X6",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:52:58.549506Z",
          "iopub.execute_input": "2021-06-15T02:52:58.549876Z",
          "iopub.status.idle": "2021-06-15T02:52:58.556093Z",
          "shell.execute_reply.started": "2021-06-15T02:52:58.549844Z",
          "shell.execute_reply": "2021-06-15T02:52:58.555030Z"
        },
        "trusted": true
      },
      "source": [
        "import os\n",
        "def getFiles(filepath):\n",
        "\n",
        "    left_fold  = 'training/image_2/'\n",
        "    right_fold = 'training/image_3/'\n",
        "    labels = 'training/label_2/'\n",
        "    filenames = [f.split(\".\")[0] for f in os.listdir(filepath+labels)]\n",
        "    # print(filenames[:10])\n",
        "\n",
        "    left_train  = [filepath+left_fold+f\"{f}.png\" for f in filenames]\n",
        "    right_train = [filepath+right_fold+f\"{f}.png\" for f in filenames]\n",
        "    labels_train = [filepath+labels + f\"{f}.txt\" for f in filenames]\n",
        "    \n",
        "    return left_train, right_train, labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHZNzVjp4C_h",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:00.366612Z",
          "iopub.execute_input": "2021-06-15T02:53:00.366975Z",
          "iopub.status.idle": "2021-06-15T02:53:00.386021Z",
          "shell.execute_reply.started": "2021-06-15T02:53:00.366947Z",
          "shell.execute_reply": "2021-06-15T02:53:00.385136Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "class customDataset(Dataset): \n",
        "    def __init__(self, source_dir, transform=None, transform_disp=None, train=False):\n",
        "        super().__init__()\n",
        "        self.source_dir = source_dir\n",
        "        self.left, self.right, self.labels = getFiles(self.source_dir)\n",
        "        assert len(self.left) == len(self.right) == len(self.labels)\n",
        "        self.tfms = transform\n",
        "        self.tfms_disp = transform_disp\n",
        "        self.train = train\n",
        "        \n",
        "        # for disparity calculation\n",
        "        self.left_matcher = cv2.StereoSGBM_create(\n",
        "            minDisparity = 0,\n",
        "            numDisparities= 128, \n",
        "            blockSize=15,\n",
        "            speckleRange=2\n",
        "        )\n",
        "\n",
        "        self.baseline = 0.54\n",
        "        self.focal_length = 721.5377\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.left) \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        left_img = io.imread(self.left[idx])\n",
        "        left_img = cv2.cvtColor(left_img, cv2.COLOR_BGRA2BGR)\n",
        "        right_img = io.imread(self.right[idx])\n",
        "        right_img = cv2.cvtColor(right_img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "        ## RGB TO single channel for disparity computation\n",
        "        monoL = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
        "        monoR = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        ## Disparity computation\n",
        "        left_disp = self.left_matcher.compute(monoL, monoR)\n",
        "\n",
        "        ## Depth       \n",
        "        depth = (self.baseline * self.focal_length) / (left_disp)\n",
        "        depth = np.clip(depth, 0, 10)\n",
        "        depth = np.array(depth, dtype=np.float32)\n",
        "\n",
        "        labels = pd.read_csv(\n",
        "            self.labels[idx],\n",
        "            names=[\"class\", \"trunc\", \"occ\", \"alpha\", \"left\", \"top\", \"right\", \"bottom\", \"height\", \"width\", \"depth\", \"locx\", \"locy\", \"locz\", \"rot\", \"score\"], \n",
        "            sep=\" \"\n",
        "        )\n",
        "        \n",
        "        # print(labels)\n",
        "        if self.train is True:\n",
        "            labels = labels[['class',  'left',  'top',  'right',  'bottom',  'height',  'width',  'depth',  'locx',  'locy',  'locz',  'rot', \"alpha\"]]\n",
        "            for c in classes:\n",
        "                labels.insert(0, c, 0.)\n",
        "                for i in labels.index:\n",
        "                    if labels.loc[i, \"class\"] == c:\n",
        "                        labels.loc[i, c] = 1.\n",
        "            labels = labels.drop('class', axis=1)\n",
        "            labels = labels.to_numpy()\n",
        "            # print(labels.shape)\n",
        "            ## scale labels to resize image size\n",
        "            labels[:,9] = labels[:,9]  \n",
        "            labels[:,11] = labels[:,11]\n",
        "            labels[:,10] = labels[:,10]\n",
        "            labels[:,12] = labels[:,12]\n",
        "\n",
        "            targ = torch.zeros((32,32,21))\n",
        "            x_center = ((labels[:,9] + labels[:,11])/2)*256/org_w # x_center of 2d bounding box\n",
        "            y_center = ((labels[:,10] + labels[:,12])/2)*256/org_h # y_center of 2d bounding box\n",
        "\n",
        "            grid_size = 256 / 32 # number of cells in \n",
        "            anchor_x = np.clip(np.array(x_center/grid_size).astype(int), 0, 31) # horizontal index where label is stored\n",
        "            anchor_y = np.clip(np.array(y_center/grid_size).astype(int), 0, 31) # vertical index where label is stored\n",
        "\n",
        "            for i, (y, x) in enumerate(zip(anchor_y, anchor_x)):\n",
        "                targ[y,x] = torch.from_numpy(labels[i])\n",
        "            \n",
        "            targ = targ.permute(2,0,1)\n",
        "\n",
        "            if self.tfms is not None:\n",
        "                left_img = self.tfms(left_img)\n",
        "                right_img = self.tfms(right_img)\n",
        "                depth = self.tfms_disp(depth)\n",
        "                img_tensor = torch.cat((left_img, right_img, depth), 0)\n",
        "                # print(img_tensor.shape)\n",
        "                # img_tensor = img_tensor.view(6,370,1224)\n",
        "                # targ = self.tfms(targ)\n",
        "                \n",
        "                return img_tensor, targ\n",
        "            return left_img, right_img, depth, targ\n",
        "        return left_img, right_img, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucSxOxHfMNI1",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:01.367131Z",
          "iopub.execute_input": "2021-06-15T02:53:01.367469Z",
          "iopub.status.idle": "2021-06-15T02:53:01.372623Z",
          "shell.execute_reply.started": "2021-06-15T02:53:01.367440Z",
          "shell.execute_reply": "2021-06-15T02:53:01.371763Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c513155-27b3-4828-e27b-dbb8e8e190a3"
      },
      "source": [
        "classes = ['Car', 'Van',  'Truck', 'Pedestrian',  'Person_sitting', 'Cyclist',  'Tram', 'Misc', 'DontCare']\n",
        "print(len(classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU8rCTp9haey",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:01.843987Z",
          "iopub.execute_input": "2021-06-15T02:53:01.844322Z",
          "iopub.status.idle": "2021-06-15T02:53:01.849564Z",
          "shell.execute_reply.started": "2021-06-15T02:53:01.844292Z",
          "shell.execute_reply": "2021-06-15T02:53:01.848601Z"
        },
        "trusted": true
      },
      "source": [
        "# IMAGE SIZE\n",
        "org_h, org_w = 375, 1242\n",
        "# org_h, org_w = 370, 1224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1-__Glcyazn",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:02.393797Z",
          "iopub.execute_input": "2021-06-15T02:53:02.394124Z",
          "iopub.status.idle": "2021-06-15T02:53:02.399839Z",
          "shell.execute_reply.started": "2021-06-15T02:53:02.394095Z",
          "shell.execute_reply": "2021-06-15T02:53:02.398998Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "load_height = 256\n",
        "load_width = 256\n",
        "\n",
        "tfms_train = transforms.Compose([    \n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((load_height, load_width)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])                \n",
        "])\n",
        "\n",
        "tfms_depth_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((load_height, load_width)),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OmnJFB1y5XS"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxX0_PHdZ2Hw",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:04.180317Z",
          "iopub.execute_input": "2021-06-15T02:53:04.180634Z",
          "iopub.status.idle": "2021-06-15T02:53:04.185342Z",
          "shell.execute_reply.started": "2021-06-15T02:53:04.180606Z",
          "shell.execute_reply": "2021-06-15T02:53:04.184270Z"
        },
        "trusted": true
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCha_mjRlZAk"
      },
      "source": [
        "## HRnet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_malX3ULl5ws"
      },
      "source": [
        "### HRnet base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGqCMLadlfQp",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:06.428905Z",
          "iopub.execute_input": "2021-06-15T02:53:06.429627Z",
          "iopub.status.idle": "2021-06-15T02:53:06.494873Z",
          "shell.execute_reply.started": "2021-06-15T02:53:06.429577Z",
          "shell.execute_reply": "2021-06-15T02:53:06.493268Z"
        },
        "trusted": true
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, momentum=0.1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, momentum=0.1)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=0.1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, momentum=0.1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, momentum=0.1)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "class HighResolutionModule(nn.Module):\n",
        "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
        "                 num_channels, fuse_method, multi_scale_output=True):\n",
        "        super().__init__()\n",
        "        self._check_branches(\n",
        "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
        "\n",
        "        self.num_inchannels = num_inchannels\n",
        "        self.fuse_method = fuse_method\n",
        "        self.num_branches = num_branches\n",
        "\n",
        "        self.multi_scale_output = multi_scale_output\n",
        "\n",
        "        self.branches = self._make_branches(\n",
        "            num_branches, blocks, num_blocks, num_channels)\n",
        "        self.fuse_layers = self._make_fuse_layers()\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
        "                        num_inchannels, num_channels):\n",
        "        if num_branches != len(num_blocks):\n",
        "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
        "                num_branches, len(num_blocks))\n",
        "            logger.error(error_msg)\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        if num_branches != len(num_channels):\n",
        "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
        "                num_branches, len(num_channels))\n",
        "            logger.error(error_msg)\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        if num_branches != len(num_inchannels):\n",
        "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
        "                num_branches, len(num_inchannels))\n",
        "            logger.error(error_msg)\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
        "                         stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or \\\n",
        "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.num_inchannels[branch_index],\n",
        "                          num_channels[branch_index] * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
        "                            momentum=0.1),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.num_inchannels[branch_index],\n",
        "                            num_channels[branch_index], stride, downsample))\n",
        "        self.num_inchannels[branch_index] = \\\n",
        "            num_channels[branch_index] * block.expansion\n",
        "        for i in range(1, num_blocks[branch_index]):\n",
        "            layers.append(block(self.num_inchannels[branch_index],\n",
        "                                num_channels[branch_index]))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
        "        branches = []\n",
        "\n",
        "        for i in range(num_branches):\n",
        "            branches.append(\n",
        "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
        "\n",
        "        return nn.ModuleList(branches)\n",
        "\n",
        "    def _make_fuse_layers(self):\n",
        "        if self.num_branches == 1:\n",
        "            return None\n",
        "\n",
        "        num_branches = self.num_branches\n",
        "        num_inchannels = self.num_inchannels\n",
        "        fuse_layers = []\n",
        "        for i in range(num_branches if self.multi_scale_output else 1):\n",
        "            fuse_layer = []\n",
        "            for j in range(num_branches):\n",
        "                if j > i:\n",
        "                    fuse_layer.append(nn.Sequential(\n",
        "                        nn.Conv2d(num_inchannels[j],\n",
        "                                  num_inchannels[i],\n",
        "                                  1,\n",
        "                                  1,\n",
        "                                  0,\n",
        "                                  bias=False),\n",
        "                        nn.BatchNorm2d(num_inchannels[i], momentum=0.1)))\n",
        "                elif j == i:\n",
        "                    fuse_layer.append(None)\n",
        "                else:\n",
        "                    conv3x3s = []\n",
        "                    for k in range(i-j):\n",
        "                        if k == i - j - 1:\n",
        "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
        "                            conv3x3s.append(nn.Sequential(\n",
        "                                nn.Conv2d(num_inchannels[j],\n",
        "                                          num_outchannels_conv3x3,\n",
        "                                          3, 2, 1, bias=False),\n",
        "                                nn.BatchNorm2d(num_outchannels_conv3x3, \n",
        "                                            momentum=0.1)))\n",
        "                        else:\n",
        "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
        "                            conv3x3s.append(nn.Sequential(\n",
        "                                nn.Conv2d(num_inchannels[j],\n",
        "                                          num_outchannels_conv3x3,\n",
        "                                          3, 2, 1, bias=False),\n",
        "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
        "                                            momentum=0.1),\n",
        "                                nn.ReLU(inplace=False)))\n",
        "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
        "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
        "\n",
        "        return nn.ModuleList(fuse_layers)\n",
        "\n",
        "    def get_num_inchannels(self):\n",
        "        return self.num_inchannels\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.num_branches == 1:\n",
        "            return [self.branches[0](x[0])]\n",
        "\n",
        "        for i in range(self.num_branches):\n",
        "            x[i] = self.branches[i](x[i])\n",
        "\n",
        "        x_fuse = []\n",
        "        for i in range(len(self.fuse_layers)):\n",
        "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
        "            for j in range(1, self.num_branches):\n",
        "                if i == j:\n",
        "                    y = y + x[j]\n",
        "                elif j > i:\n",
        "                    width_output = x[i].shape[-1]\n",
        "                    height_output = x[i].shape[-2]\n",
        "                    y = y + F.interpolate(\n",
        "                        self.fuse_layers[i][j](x[j]),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear',\n",
        "                        align_corners=True)\n",
        "                else:\n",
        "                    y = y + self.fuse_layers[i][j](x[j])\n",
        "            x_fuse.append(self.relu(y))\n",
        "\n",
        "        return x_fuse\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dohwDDfHl5QK"
      },
      "source": [
        "### Regular HRnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRqg3HVemACv",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:08.723549Z",
          "iopub.execute_input": "2021-06-15T02:53:08.723917Z",
          "iopub.status.idle": "2021-06-15T02:53:08.763154Z",
          "shell.execute_reply.started": "2021-06-15T02:53:08.723888Z",
          "shell.execute_reply": "2021-06-15T02:53:08.762170Z"
        },
        "trusted": true
      },
      "source": [
        "blocks_dict = {\n",
        "    'BASIC': BasicBlock,\n",
        "    'BOTTLENECK': Bottleneck\n",
        "}\n",
        "class HighResolutionNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # stem net\n",
        "        self.conv1 = nn.Conv2d(7, 64, kernel_size=5, stride=1, padding=2,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, momentum=0.1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64, momentum=0.1)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "        self.stage1_cfg = {\n",
        "            'NUM_MODULES' : 1,\n",
        "            'NUM_BRANCHES' : 1,\n",
        "            'NUM_BLOCKS' : [4],\n",
        "            'NUM_CHANNELS' : [16],\n",
        "            'BLOCK' : 'BOTTLENECK',\n",
        "            'FUSE_METHOD' : 'SUM',\n",
        "\n",
        "        }\n",
        "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
        "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
        "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
        "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
        "        stage1_out_channel = block.expansion*num_channels\n",
        "\n",
        "        self.stage2_cfg = {\n",
        "            'NUM_MODULES' : 1,\n",
        "            'NUM_BRANCHES' : 2,\n",
        "            'NUM_BLOCKS' : [4, 4],\n",
        "            'NUM_CHANNELS' : [16, 32],\n",
        "            'BLOCK' : 'BASIC',\n",
        "            'FUSE_METHOD' : 'SUM',\n",
        "\n",
        "        }\n",
        "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition1 = self._make_transition_layer(\n",
        "            [stage1_out_channel], num_channels)\n",
        "        self.stage2, pre_stage_channels = self._make_stage(\n",
        "            self.stage2_cfg, num_channels)\n",
        "\n",
        "        self.stage3_cfg = {\n",
        "            'NUM_MODULES' : 1,\n",
        "            'NUM_BRANCHES' : 3,\n",
        "            'NUM_BLOCKS' : [4, 4, 4],\n",
        "            'NUM_CHANNELS' : [16, 32, 64],\n",
        "            'BLOCK' : 'BASIC',\n",
        "            'FUSE_METHOD' : 'SUM',\n",
        "\n",
        "        }\n",
        "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition2 = self._make_transition_layer(\n",
        "            pre_stage_channels, num_channels)\n",
        "        self.stage3, pre_stage_channels = self._make_stage(\n",
        "            self.stage3_cfg, num_channels)\n",
        "        self.stage4_cfg = {\n",
        "            'NUM_MODULES' : 1,\n",
        "            'NUM_BRANCHES' : 4,\n",
        "            'NUM_BLOCKS' : [4, 4, 4, 4],\n",
        "            'NUM_CHANNELS' : [16, 32, 64, 128],\n",
        "            'BLOCK' : 'BASIC',\n",
        "            'FUSE_METHOD' : 'SUM',\n",
        "\n",
        "        }\n",
        "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
        "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
        "        num_channels = [\n",
        "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
        "        self.transition3 = self._make_transition_layer(\n",
        "            pre_stage_channels, num_channels)\n",
        "        self.stage4, pre_stage_channels = self._make_stage(\n",
        "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
        "\n",
        "        last_inp_channels = int(np.sum(pre_stage_channels))\n",
        "        last_out_channels = 21\n",
        "        self.second_last_layer = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=4),\n",
        "            nn.Conv2d(\n",
        "                in_channels=last_inp_channels,\n",
        "                out_channels=last_inp_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1),\n",
        "            nn.BatchNorm2d(last_inp_channels, momentum=0.1),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(\n",
        "                in_channels=last_inp_channels,\n",
        "                out_channels=last_inp_channels,\n",
        "                kernel_size=1)\n",
        "            \n",
        "        )\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Linear(last_inp_channels, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, last_out_channels),\n",
        "        )\n",
        "        self.prob_layer = nn.Sigmoid()\n",
        "\n",
        "    def _make_transition_layer(\n",
        "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
        "        num_branches_cur = len(num_channels_cur_layer)\n",
        "        num_branches_pre = len(num_channels_pre_layer)\n",
        "\n",
        "        transition_layers = []\n",
        "        for i in range(num_branches_cur):\n",
        "            if i < num_branches_pre:\n",
        "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
        "                    transition_layers.append(nn.Sequential(\n",
        "                        nn.Conv2d(num_channels_pre_layer[i],\n",
        "                                  num_channels_cur_layer[i],\n",
        "                                  3,\n",
        "                                  1,\n",
        "                                  1,\n",
        "                                  bias=False),\n",
        "                        nn.BatchNorm2d(\n",
        "                            num_channels_cur_layer[i], momentum=0.1),\n",
        "                        nn.ReLU(inplace=False)))\n",
        "                else:\n",
        "                    transition_layers.append(None)\n",
        "            else:\n",
        "                conv3x3s = []\n",
        "                for j in range(i+1-num_branches_pre):\n",
        "                    inchannels = num_channels_pre_layer[-1]\n",
        "                    outchannels = num_channels_cur_layer[i] \\\n",
        "                        if j == i-num_branches_pre else inchannels\n",
        "                    conv3x3s.append(nn.Sequential(\n",
        "                        nn.Conv2d(\n",
        "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
        "                        nn.BatchNorm2d(outchannels, momentum=0.1),\n",
        "                        nn.ReLU(inplace=False)))\n",
        "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
        "\n",
        "        return nn.ModuleList(transition_layers)\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=0.1),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_stage(self, layer_config, num_inchannels,\n",
        "                    multi_scale_output=True):\n",
        "        num_modules = layer_config['NUM_MODULES']\n",
        "        num_branches = layer_config['NUM_BRANCHES']\n",
        "        num_blocks = layer_config['NUM_BLOCKS']\n",
        "        num_channels = layer_config['NUM_CHANNELS']\n",
        "        block = blocks_dict[layer_config['BLOCK']]\n",
        "        fuse_method = layer_config['FUSE_METHOD']\n",
        "\n",
        "        modules = []\n",
        "        for i in range(num_modules):\n",
        "            # multi_scale_output is only used last module\n",
        "            if not multi_scale_output and i == num_modules - 1:\n",
        "                reset_multi_scale_output = False\n",
        "            else:\n",
        "                reset_multi_scale_output = True\n",
        "            modules.append(\n",
        "                HighResolutionModule(num_branches,\n",
        "                                      block,\n",
        "                                      num_blocks,\n",
        "                                      num_inchannels,\n",
        "                                      num_channels,\n",
        "                                      fuse_method,\n",
        "                                      reset_multi_scale_output)\n",
        "            )\n",
        "            num_inchannels = modules[-1].get_num_inchannels()\n",
        "\n",
        "        return nn.Sequential(*modules), num_inchannels\n",
        "\n",
        "    def forward(self, x ):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "\n",
        "        x_list = []\n",
        "        for i in range(2):\n",
        "            if self.transition1[i] is not None:\n",
        "                x_list.append(self.transition1[i](x))\n",
        "            else:\n",
        "                x_list.append(x)\n",
        "        y_list = self.stage2(x_list)\n",
        "\n",
        "        x_list = []\n",
        "        for i in range(3):\n",
        "            if self.transition2[i] is not None:\n",
        "                if i < 2:\n",
        "                    x_list.append(self.transition2[i](y_list[i]))\n",
        "                else:\n",
        "                    x_list.append(self.transition2[i](y_list[-1]))\n",
        "            else:\n",
        "                x_list.append(y_list[i])\n",
        "        y_list = self.stage3(x_list)\n",
        "\n",
        "        x_list = []\n",
        "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
        "            if self.transition3[i] is not None:\n",
        "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
        "                    x_list.append(self.transition3[i](y_list[i]))\n",
        "                else:\n",
        "                    x_list.append(self.transition3[i](y_list[-1]))\n",
        "            else:\n",
        "                x_list.append(y_list[i])\n",
        "        x = self.stage4(x_list)\n",
        "\n",
        "#         # Upsampling\n",
        "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
        "\n",
        "        x1 = F.interpolate(x[1], size=(x0_h, x0_w), mode='bilinear', align_corners=True)\n",
        "        x2 = F.interpolate(x[2], size=(x0_h, x0_w), mode='bilinear', align_corners=True)\n",
        "        x3 = F.interpolate(x[3], size=(x0_h, x0_w), mode='bilinear', align_corners=True)\n",
        "        x = torch.cat([x[0], x1, x2, x3], 1)\n",
        "\n",
        "        x = self.second_last_layer(x)\n",
        "#         print(x.shape)\n",
        "        x = x.permute(0,2,3,1)\n",
        "#         print(x.shape)\n",
        "        x = self.last_layer(x)\n",
        "#         print(x.shape)\n",
        "        x = x.permute(0,3,1,2)\n",
        "#         print(x.shape)\n",
        "        x = torch.cat((self.prob_layer(x[:,:9,:,:]), x[:,9:,:,:]), dim=1)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqDGMJn1muqG",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae61845-9fed-4033-8243-7aa79ed1faae"
      },
      "source": [
        "## sanity check for model output\n",
        "def test():\n",
        "    model = HighResolutionNet()\n",
        "    inp = torch.rand((1,7,256,256)) * 1e4\n",
        "    out = model(inp)\n",
        "    print(type(out))\n",
        "    print(out.shape)\n",
        "    print(out[0,:,0,0])\n",
        "    del model\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 21, 32, 32])\n",
            "tensor([ 0.5213,  0.4495,  0.4881,  0.4778,  0.5833,  0.4631,  0.4816,  0.5363,\n",
            "         0.5750, -0.0445, -0.1609,  0.1102,  0.0632,  0.0185, -0.0597, -0.1239,\n",
            "        -0.1185, -0.2164, -0.3708,  0.3068, -0.2041], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIz22D1OtYoz"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBEwjPtTiolw",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:21.477866Z",
          "iopub.execute_input": "2021-06-15T02:53:21.478190Z",
          "iopub.status.idle": "2021-06-15T02:53:21.529824Z",
          "shell.execute_reply.started": "2021-06-15T02:53:21.478160Z",
          "shell.execute_reply": "2021-06-15T02:53:21.528913Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fa7df9-5ad8-4c1f-ddd5-1dfe599a3b04"
      },
      "source": [
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "print(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBqRBO7wiXEb",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:21.821442Z",
          "iopub.execute_input": "2021-06-15T02:53:21.821772Z",
          "iopub.status.idle": "2021-06-15T02:53:21.825937Z",
          "shell.execute_reply.started": "2021-06-15T02:53:21.821741Z",
          "shell.execute_reply": "2021-06-15T02:53:21.824720Z"
        },
        "trusted": true
      },
      "source": [
        "MSE_loss = nn.MSELoss()\n",
        "BCE_loss = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMZSnt2M-TXY",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:22.098538Z",
          "iopub.execute_input": "2021-06-15T02:53:22.098880Z",
          "iopub.status.idle": "2021-06-15T02:53:23.138136Z",
          "shell.execute_reply.started": "2021-06-15T02:53:22.098851Z",
          "shell.execute_reply": "2021-06-15T02:53:23.137175Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4441ae96-dd11-4812-c71b-bc49ddcef51b"
      },
      "source": [
        "\n",
        "def loss_func(pred, targ):\n",
        "    loss = 0.\n",
        "    # print(pred.shape)\n",
        "    # print(targ.shape)\n",
        "    \n",
        "    # locn = locn.squeeze()\n",
        "    # print(locn.shape)\n",
        "    # print(locn)\n",
        "\n",
        "    for b in range(targ.shape[0]):\n",
        "        # 1. loss for all probabilities\n",
        "        # BCE loss is very small compared to MSE. so scale up appropriately\n",
        "        # Also if mse loss > bce loss, net will make mse loss 0 by outputing all probs = 0. hence won't learn anything\n",
        "        loss += 1e6 * BCE_loss(pred[:,:9,:,:], targ[:,:9,:,:])\n",
        "        \n",
        "        # 2. all boxes where prob = 1\n",
        "        mse = 0.\n",
        "        for i in range(targ.shape[2]):\n",
        "            for j in range(targ.shape[3]):\n",
        "                if torch.sum(targ[b,:9,i,j]).item() > 1e-2 :\n",
        "                    loss += MSE_loss(pred[b,9:,i,j], targ[b,9:,i,j]) \n",
        "    return loss\n",
        "\n",
        "## test loss func\n",
        "a = torch.rand((16,21,32,32))\n",
        "b = torch.rand((16,21,32,32))\n",
        "print(loss_func(a,b).item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15974813.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVErRykNj4xP"
      },
      "source": [
        "# TRAIN with Fastai "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMMqWijRbXm9",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:24.912509Z",
          "iopub.execute_input": "2021-06-15T02:53:24.912955Z",
          "iopub.status.idle": "2021-06-15T02:53:25.770371Z",
          "shell.execute_reply.started": "2021-06-15T02:53:24.912917Z",
          "shell.execute_reply": "2021-06-15T02:53:25.769499Z"
        },
        "trusted": true
      },
      "source": [
        "# Fastai instead\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.vision.data import *\n",
        "# from fastai.vision.core import *\n",
        "from fastai.vision.data import DataLoader as FastLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmVlwAFzdZK",
        "outputId": "37efea97-3128-4a6d-df08-4c7c264f34ed"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 16 06:57:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P8    21W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCTHZMnuFyS9",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:26.640704Z",
          "iopub.execute_input": "2021-06-15T02:53:26.641040Z",
          "iopub.status.idle": "2021-06-15T02:53:26.649048Z",
          "shell.execute_reply.started": "2021-06-15T02:53:26.641011Z",
          "shell.execute_reply": "2021-06-15T02:53:26.647781Z"
        },
        "trusted": true
      },
      "source": [
        "# new dataset with train and validation split for fastai\n",
        "class FastDataset(customDataset):\n",
        "    def __init__(self, train=False, split_pct=0.8, source_dir=None, tfms=None, tfms_disp=None):\n",
        "        super().__init__(source_dir, transform=tfms, transform_disp=tfms_disp, train=True)\n",
        "\n",
        "        split = int(len(self) * split_pct)\n",
        "        if train==True:\n",
        "            self.left = self.left[:split]\n",
        "            self.right = self.right[:split]\n",
        "            self.labels = self.labels[:split]\n",
        "        else:\n",
        "            self.left = self.left[-split:]\n",
        "            self.right = self.right[-split:]\n",
        "            self.labels = self.labels[-split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_GhW_FZIxnh",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:30.749334Z",
          "iopub.execute_input": "2021-06-15T02:53:30.749656Z",
          "iopub.status.idle": "2021-06-15T02:53:30.914642Z",
          "shell.execute_reply.started": "2021-06-15T02:53:30.749624Z",
          "shell.execute_reply": "2021-06-15T02:53:30.913821Z"
        },
        "trusted": true
      },
      "source": [
        "PATH = \"\"\n",
        "train_ds = FastDataset(\n",
        "    train=True, \n",
        "    split_pct=0.95, \n",
        "    source_dir=PATH, \n",
        "    tfms=tfms_train, \n",
        "    tfms_disp=tfms_depth_train\n",
        ")\n",
        "valid_ds = FastDataset(\n",
        "    train=False, \n",
        "    split_pct=0.05, \n",
        "    source_dir=PATH, \n",
        "    tfms=tfms_train, \n",
        "    tfms_disp=tfms_depth_train\n",
        ")\n",
        "train_loader = FastLoader(train_ds, batch_size=4, shuffle=True, num_workers = 2, pin_memory=False)\n",
        "valid_loader = FastLoader(valid_ds, batch_size=4, shuffle=True, num_workers = 2, pin_memory=False)\n",
        "\n",
        "\n",
        "db = DataBunch(train_dl=train_loader, valid_dl=valid_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZwiQrPSbelI",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:28.218255Z",
          "iopub.execute_input": "2021-06-15T02:53:28.218575Z",
          "iopub.status.idle": "2021-06-15T02:53:28.222751Z",
          "shell.execute_reply.started": "2021-06-15T02:53:28.218545Z",
          "shell.execute_reply": "2021-06-15T02:53:28.221625Z"
        },
        "trusted": true
      },
      "source": [
        "import imageio as io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-15T02:53:35.547058Z",
          "iopub.execute_input": "2021-06-15T02:53:35.547401Z",
          "iopub.status.idle": "2021-06-15T02:54:02.700103Z",
          "shell.execute_reply.started": "2021-06-15T02:53:35.547372Z",
          "shell.execute_reply": "2021-06-15T02:54:02.699089Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHme0qRfzdZL",
        "outputId": "baaa6314-8c4c-4b1b-bd47-d7c143abdb42"
      },
      "source": [
        "batch = next(iter(db.valid_dl))\n",
        "inp, targ = batch\n",
        "print(inp.shape)\n",
        "print(targ.shape)\n",
        "print(len(batch))\n",
        "print(len(db.valid_ds))\n",
        "print(len(db.train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 7, 256, 256])\n",
            "torch.Size([16, 21, 32, 32])\n",
            "2\n",
            "374\n",
            "7106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgBTrg2Uxa98"
      },
      "source": [
        "\n",
        " TARGET_VECTOR = [<one-hot-vector for 9 classes == 9 0/1s>, left, top, bottom, right, ...]   \n",
        "total 20 values in single vector    \n",
        "each target matrix has 32x32 such vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpmZX6ijdyGs",
        "trusted": true
      },
      "source": [
        "\n",
        "inp = batch[0][1]\n",
        "targ = batch[1][1]\n",
        "print(targ.shape)\n",
        "left = inp[:3].cpu()\n",
        "right = inp[3:].cpu()\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10,10) )\n",
        "ax[0].imshow(left.permute(1,2,0))\n",
        "ax[1].imshow(right.permute(1,2,0))\n",
        "\n",
        "## check target\n",
        "for i in range(targ.shape[1]):\n",
        "    for j in range(targ.shape[2]):\n",
        "        if torch.sum(targ[:9,i,j])!=0:\n",
        "            print(targ[:9,i,j])\n",
        "            x_targ = targ[9,i,j]\n",
        "            y_targ = targ[10,i,j]\n",
        "            w_targ = targ[11,i,j] - targ[9,i,j]\n",
        "            h_targ = targ[12,i,j] - targ[10,i,j]\n",
        "            x_targ = x_targ *256/org_w\n",
        "            y_targ = y_targ *256/org_h\n",
        "            w_targ = w_targ *256/org_w\n",
        "            h_targ = h_targ *256/org_h\n",
        "            # print(targ[i,j,12], targ[i,j,10], targ[i,j,12] - targ[i,j,10])\n",
        "            rect_targ = patches.Rectangle((x_targ,y_targ), w_targ, h_targ, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # targ_boxes.append(rect)\n",
        "            ax[0].add_patch(rect_targ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EcljrTmz_ZS",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:54:08.938024Z",
          "iopub.execute_input": "2021-06-15T02:54:08.938360Z",
          "iopub.status.idle": "2021-06-15T02:54:09.601464Z",
          "shell.execute_reply.started": "2021-06-15T02:54:08.938324Z",
          "shell.execute_reply": "2021-06-15T02:54:09.600394Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd7510f-77e5-4867-ce0b-770ec9989005"
      },
      "source": [
        "\n",
        "path_to_save = \"StereoHRnet/\"\n",
        "# !mkdir {path_to_save}\n",
        "! cd {path_to_save}; ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ0IVtCfbpRA",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:54:11.661073Z",
          "iopub.execute_input": "2021-06-15T02:54:11.661405Z",
          "iopub.status.idle": "2021-06-15T02:54:11.807097Z",
          "shell.execute_reply.started": "2021-06-15T02:54:11.661372Z",
          "shell.execute_reply": "2021-06-15T02:54:11.806001Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62461985-dd30-4f2b-da31-cfe9a140c395"
      },
      "source": [
        "from fastai import callbacks\n",
        "learn = Learner(data=db, model=HighResolutionNet(),opt_func=optim.Adam, loss_func=loss_func, path=path_to_save)\n",
        "print(learn.data.device)\n",
        "Callbacks = [callbacks.SaveModelCallback(learn, every=\"epoch\", name=\"model_epoch\")]\n",
        "\n",
        "learn.callbacks = Callbacks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkSsczl1jvOM"
      },
      "source": [
        "learn.load(\"model_epoch_15\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0lTysCmKPZF",
        "trusted": true
      },
      "source": [
        "learn.lr_find(start_lr = 1e-10, end_lr = 1e2, num_it=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkw15u3zbYHE",
        "trusted": true
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84kGJ5v56I3N",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54a6342-d547-4d57-c4a3-1f7861cfe1ed"
      },
      "source": [
        "\n",
        "inp, targ = batch\n",
        "with torch.no_grad():\n",
        "    inp = inp\n",
        "    targ = targ\n",
        "    pred = learn.model(inp)\n",
        "    loss = learn.loss_func(pred, targ)\n",
        "    print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1479e+08, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZuVXErovHb",
        "execution": {
          "iopub.status.busy": "2021-06-15T02:54:26.581320Z",
          "iopub.execute_input": "2021-06-15T02:54:26.581637Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "a27957e0-621c-4c1b-d54a-e0b5cff7e818"
      },
      "source": [
        "# learn.fit(4, 1e-5)\n",
        "with np.errstate(divide='ignore'):\n",
        "    learn.fit_one_cycle(40, max_lr = 1e-2, start_epoch=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model_epoch_15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/24 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1777' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1777 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-738feee0794c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learn.fit(4, 1e-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4f530e5e2739>\u001b[0m in \u001b[0;36mloss_func\u001b[0;34m(pred, targ)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-2\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mMSE_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bM6cu2aYzdZR"
      },
      "source": [
        "\"hello\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orq7F9tZu94p"
      },
      "source": [
        "# inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvRWsxyMu_h-"
      },
      "source": [
        "net = Net().to(dev)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx3JMaB4wa0J"
      },
      "source": [
        "\n",
        "params = torch.load(f\"{path_to_save}models/bestmodel.pth\")\n",
        "# params['model']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAKbMiXkw_Z2"
      },
      "source": [
        "\n",
        "net.load_state_dict(params['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16SFrYjBxkUF",
        "trusted": true
      },
      "source": [
        "\n",
        "inp = batch[0][2]\n",
        "targ = batch[1][2]\n",
        "print(targ.shape)\n",
        "left = inp[:3].cpu()\n",
        "right = inp[3:6].cpu()\n",
        "depth = inp[6:].cpu()\n",
        "fig, ax = plt.subplots(2, 2, figsize=(10,10))\n",
        "ax[0,0].imshow(left.permute(1,2,0))\n",
        "ax[0,1].imshow(right.permute(1,2,0))\n",
        "ax[1,0].imshow(depth.unsqueeze(0))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = learn.model(inp.unsqueeze(0)).squeeze().cpu()\n",
        "    \n",
        "## check target\n",
        "for i in range(targ.shape[1]):\n",
        "    for j in range(targ.shape[2]):\n",
        "        if torch.sum(targ[:9,i,j])!=0:\n",
        "#             print(targ[:,i,j])\n",
        "            x_targ = targ[9,i,j]\n",
        "            y_targ = targ[10,i,j]\n",
        "            w_targ = targ[11,i,j] - targ[9,i,j]\n",
        "            h_targ = targ[12,i,j] - targ[10,i,j]\n",
        "            x_targ = x_targ *256/org_w\n",
        "            y_targ = y_targ *256/org_h\n",
        "            w_targ = w_targ *256/org_w\n",
        "            h_targ = h_targ *256/org_h\n",
        "            # print(targ[i,j,12], targ[i,j,10], targ[i,j,12] - targ[i,j,10])\n",
        "            rect_targ = patches.Rectangle((x_targ,y_targ), w_targ, h_targ, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # targ_boxes.append(rect)\n",
        "            ax[0,0].add_patch(rect_targ)\n",
        "            \n",
        "            # PREDICTIONS\n",
        "#             print(pred[:,i,j])\n",
        "            x_pred = pred[9,i,j]\n",
        "            y_pred = pred[10,i,j]\n",
        "            w_pred = pred[11,i,j] - pred[9,i,j]\n",
        "            h_pred = pred[12,i,j] - pred[10,i,j]\n",
        "            x_pred = x_pred *256/org_w\n",
        "            y_pred = y_pred *256/org_h\n",
        "            w_pred = w_pred *256/org_w\n",
        "            h_pred = h_pred *256/org_h\n",
        "            # print(targ[i,j,12], targ[i,j,10], targ[i,j,12] - targ[i,j,10])\n",
        "            rect_pred = patches.Rectangle((x_pred,y_pred), w_pred, h_pred, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # targ_boxes.append(rect)\n",
        "            ax[1,0].add_patch(rect_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MGRjHkHfzdZT"
      },
      "source": [
        "   \n",
        "fig, ax = plt.subplots(1,2, figsize=(10,10) )\n",
        "ax[0].imshow(left.permute(1,2,0))\n",
        "ax[1].imshow(right.permute(1,2,0))\n",
        "for i in range(pred.shape[1]):\n",
        "    for j in range(pred.shape[2]):\n",
        "        p = [p>1e-2 for p in pred[:9,i,j]]\n",
        "\n",
        "        if sum(p) > 0:\n",
        "            \n",
        "            # PREDICTIONS\n",
        "#             print(pred[:9,i,j])\n",
        "            x_pred = pred[9,i,j]\n",
        "            y_pred = pred[10,i,j]\n",
        "            w_pred = pred[11,i,j] - pred[9,i,j]\n",
        "            h_pred = pred[12,i,j] - pred[10,i,j]\n",
        "            x_pred = x_pred *256/org_w\n",
        "            y_pred = y_pred *256/org_h\n",
        "            w_pred = w_pred *256/org_w\n",
        "            h_pred = h_pred *256/org_h\n",
        "            # print(targ[i,j,12], targ[i,j,10], targ[i,j,12] - targ[i,j,10])\n",
        "            rect_pred = patches.Rectangle((x_pred,y_pred), w_pred, h_pred, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # targ_boxes.append(rect)\n",
        "            ax[0].add_patch(rect_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNWeRSeDzMyy"
      },
      "source": [
        "# Train some more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQSupFcvzPYn",
        "trusted": true
      },
      "source": [
        "# learn.fit(4, 1e-5)\n",
        "learn.fit(2, lr = 1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Uh074A25ho"
      },
      "source": [
        "# MISC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBsGM3ju263K",
        "trusted": true
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}